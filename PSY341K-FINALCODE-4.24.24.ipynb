{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the spreadsheet into a pandas dataframe\n",
    "df = pd.read_csv('LIWCDATA-4.10.24.csv')\n",
    "\n",
    "# filter the DataFrame by father and mother\n",
    "father_df = df[df['Father (0) or Mother(1)'] == 0]\n",
    "mother_df = df[df['Father (0) or Mother(1)'] == 1]\n",
    "\n",
    "columns = list(father_df.columns[8:])\n",
    "\n",
    "mean_values = {'Columns': columns}\n",
    "\n",
    "father_means = [father_df[col].mean() for col in columns]\n",
    "mother_means = [mother_df[col].mean() for col in columns]\n",
    "\n",
    "father_sd = [father_df[col].std() for col in columns]\n",
    "mother_sd = [mother_df[col].std() for col in columns]\n",
    "\n",
    "mean_values['Father Mean'] = father_means\n",
    "mean_values['Mother Mean'] = mother_means\n",
    "\n",
    "mean_values['Father SD'] = father_sd\n",
    "mean_values['Mother SD'] = mother_sd\n",
    "\n",
    "mean_sd_df = pd.DataFrame(mean_values)\n",
    "\n",
    "print(mean_sd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sample sizes\n",
    "print('Number of father entries:', len(father_df))\n",
    "print('Number of mother entries:', len(mother_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make columns into a list for printing in each loop iteration during t test\n",
    "columns_list = mean_sd_df['Columns'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welch T-test\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# initializing list for tests that are statistically significant\n",
    "stat_diff_list = []\n",
    "\n",
    "# drop the 'Columns' column as it's not needed for the test\n",
    "mean_sd_df.drop(columns='Columns', inplace=True)\n",
    "\n",
    "def welch_t_test(mean1, sd1, n1, mean2, sd2, n2):\n",
    "    # standard error of the difference between means\n",
    "    se_diff = np.sqrt((sd1**2 / n1) + (sd2**2 / n2))\n",
    "    \n",
    "    # t-statistic calc\n",
    "    t_statistic = (mean1 - mean2) / se_diff\n",
    "    \n",
    "    # degrees of freedom\n",
    "    df = n1 + n2 - 2\n",
    "    \n",
    "    # calculate the p-value\n",
    "    p_value = 2 * (1 - t.cdf(np.abs(t_statistic), df))\n",
    "    \n",
    "    # Cohen's d calculation\n",
    "    pooled_sd = np.sqrt(((n1 - 1) * sd1 ** 2 + (n2 - 1) * sd2 ** 2) / (n1 + n2 - 2))\n",
    "    cohens_d = (mean1 - mean2) / pooled_sd\n",
    "\n",
    "    return t_statistic, p_value, cohens_d\n",
    "\n",
    "# iterate over each row (each category from LIWC)\n",
    "for index, row in mean_sd_df.iterrows():\n",
    "    col_name = columns_list[index]  # name of the row as the column name\n",
    "    father_mean, father_sd = row['Father Mean'], row['Father SD']\n",
    "    mother_mean, mother_sd = row['Mother Mean'], row['Mother SD']\n",
    "    father_n, mother_n = 240, 359  # sample sizes for father and mother\n",
    "    \n",
    "    # perform t-test\n",
    "    t_statistic, p_value, cohens_d = welch_t_test(father_mean, father_sd, father_n, mother_mean, mother_sd, mother_n)\n",
    "    \n",
    "    # print t_statistic and p_value for each LIWC category t test\n",
    "    print('For', col_name)\n",
    "    print('t-statistic:', t_statistic)\n",
    "    print('p-value:', p_value)\n",
    "    print(\"Cohen's d:\", cohens_d)\n",
    "\n",
    "    # t-test evaluation\n",
    "    \n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print('Samples are different (reject null hypothesis)')\n",
    "        stat_diff_list.append(col_name)\n",
    "\n",
    "    else:\n",
    "        print('Samples are not different (fail to reject null hypothesis)')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df = pd.read_csv('LIWCDATA-4.10.24.csv')\n",
    "\n",
    "# filter the dataframe by father and mother\n",
    "father_df = df[df['Father (0) or Mother(1)'] == 0]\n",
    "mother_df = df[df['Father (0) or Mother(1)'] == 1]\n",
    "\n",
    "# preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # remove non-alphanumeric characters except spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # get English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # split the text into words using whitespace as delimiter\n",
    "    words = text.split()\n",
    "    \n",
    "    # filter out stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "# generate word cloud function\n",
    "def generate_wordcloud(text):\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    min_font_size = 10).generate(text)\n",
    "    return wordcloud\n",
    "\n",
    "# concatenate all texts for mothers and fathers\n",
    "all_mother_text = ' '.join(preprocess_text(text) for text in mother_df['Text'])\n",
    "all_father_text = ' '.join(preprocess_text(text) for text in father_df['Text'])\n",
    "\n",
    "# generate word clouds\n",
    "mother_wordcloud = generate_wordcloud(all_mother_text)\n",
    "father_wordcloud = generate_wordcloud(all_father_text)\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mother_wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Mothers')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(father_wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Fathers')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 NGrams for Each Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# concatenate all texts for mothers and fathers\n",
    "all_mother_text = ' '.join(preprocess_text(text) for text in mother_df['Text'])\n",
    "all_father_text = ' '.join(preprocess_text(text) for text in father_df['Text'])\n",
    "\n",
    "# tokenize the text\n",
    "mother_tokens = word_tokenize(all_mother_text)\n",
    "father_tokens = word_tokenize(all_father_text)\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Filter out stopwords\n",
    "mother_tokens = [word for word in mother_tokens if word.lower() not in stop_words]\n",
    "father_tokens = [word for word in father_tokens if word.lower() not in stop_words]\n",
    "\n",
    "# get unigrams\n",
    "mother_unigrams = Counter(mother_tokens)\n",
    "father_unigrams = Counter(father_tokens)\n",
    "\n",
    "# Get bigrams\n",
    "mother_bigrams = Counter(ngrams(mother_tokens, 2))\n",
    "father_bigrams = Counter(ngrams(father_tokens, 2))\n",
    "\n",
    "# Extract most frequent unigrams (top 10)\n",
    "top_unigrams_M = mother_unigrams.most_common(10)\n",
    "top_unigrams_F = father_unigrams.most_common(10)\n",
    "\n",
    "# Extract most frequent bigrams (top 10)\n",
    "top_bigrams_M = mother_bigrams.most_common(10)\n",
    "top_bigrams_F = father_bigrams.most_common(10)\n",
    "\n",
    "print(\"Top 10 most frequent unigrams in Mothers:\")\n",
    "for unigram, count in top_unigrams_M:\n",
    "    print(f\"{unigram}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 most frequent bigrams in Mothers:\")\n",
    "for bigram, count in top_bigrams_M:\n",
    "    print(f\"{' '.join(bigram)}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 most frequent unigrams in Fathers:\")\n",
    "for unigram, count in top_unigrams_F:\n",
    "    print(f\"{unigram}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 most frequent bigrams in Fathers:\")\n",
    "for bigram, count in top_bigrams_F:\n",
    "    print(f\"{' '.join(bigram)}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
